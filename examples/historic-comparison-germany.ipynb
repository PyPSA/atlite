{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historic comparison PV and wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are examining the power feed-ins calculated by `atlite`. Based on data for capacity distributions and weather during the year 2013 in Germany, we try to match historical statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import pandas as pd\n",
    "import pgeocode\n",
    "import xarray as xr\n",
    "\n",
    "import atlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Necessary Data Files\n",
    "\n",
    "1. We need to download the locations of all the PV installations in Germany to later\n",
    "   tell atlite where to setup the PV panels and with which capacity.\n",
    "   This information is available in Germany (thanks to the EEG feed-in-tariffs in\n",
    "   the so-called \"Anlagenregister\").\n",
    "2. We also download a reference time-series to compare our results against later.\n",
    "   We retrieve the data from https://open-power-system-data.org which in return\n",
    "   gets it from ENTSO-E.\n",
    "3. Finally we also download a cutout of weather data from the ERA5 dataset containing\n",
    "   Germany and the year we want to examine (2012)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_file(url, local_filename):\n",
    "    # variant of http://stackoverflow.com/a/16696317\n",
    "    if not os.path.exists(local_filename):\n",
    "        r = requests.get(url, stream=True)\n",
    "        with open(local_filename, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    return local_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference time-series\n",
    "\n",
    "The reference is downloaded from [Open Power System Data (OPSD)](https://data.open-power-system-data.org/time_series/) and contains data reported by the\n",
    "TSOs and DSOs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_fn = download_file(\n",
    "    \"https://data.open-power-system-data.org/index.php?package=time_series&version=2019-06-05&action=customDownload&resource=3&filter%5B_contentfilter_cet_cest_timestamp%5D%5Bfrom%5D=2012-01-01&filter%5B_contentfilter_cet_cest_timestamp%5D%5Bto%5D=2013-05-01&filter%5BRegion%5D%5B%5D=DE&filter%5BVariable%5D%5B%5D=solar_generation_actual&filter%5BVariable%5D%5B%5D=wind_generation_actual&downloadCSV=Download+CSV\",\n",
    "    \"time_series_60min_singleindex_filtered.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd = pd.read_csv(opsd_fn, parse_dates=True, index_col=0)\n",
    "\n",
    "# we later use the (in current version) timezone unaware datetime64\n",
    "# to work together with this format, we have to remove the timezone\n",
    "# timezone information. We are working with UTC everywhere.\n",
    "\n",
    "opsd.index = opsd.index.tz_convert(None)\n",
    "\n",
    "# We are only interested in the 2012 data\n",
    "opsd = opsd[(\"2011\" < opsd.index) & (opsd.index < \"2013\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PV locations (\"Anlagenregister\")\n",
    "\n",
    "Download and unzip the archive containing all reported PV installations in Germany in 2011 from [energymap.info](http://www.energymap.info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_fn = download_file(\n",
    "    \"http://www.energymap.info/download/eeg_anlagenregister_2015.08.utf8.csv.zip\",\n",
    "    \"eeg_anlagenregister_2015.08.utf8.csv.zip\",\n",
    ")\n",
    "\n",
    "with zipfile.ZipFile(eeg_fn, \"r\") as zip_ref:\n",
    "    zip_ref.extract(\"eeg_anlagenregister_2015.08.utf8.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Cutout from ERA5\n",
    "\n",
    "Load the country shape for Germany and determine its geographic bounds for downloading the appropriate cutout from ECMWF's ERA5 data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.io.shapereader as shpreader\n",
    "import geopandas as gpd\n",
    "\n",
    "shp = shpreader.Reader(\n",
    "    shpreader.natural_earth(\n",
    "        resolution=\"10m\", category=\"cultural\", name=\"admin_0_countries\"\n",
    "    )\n",
    ")\n",
    "de_record = list(filter(lambda c: c.attributes[\"ISO_A2\"] == \"DE\", shp.records()))[0]\n",
    "de = pd.Series({**de_record.attributes, \"geometry\": de_record.geometry})\n",
    "x1, y1, x2, y2 = de[\"geometry\"].bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout = atlite.Cutout(\n",
    "    \"germany-2012\",\n",
    "    module=\"era5\",\n",
    "    x=slice(x1 - 0.2, x2 + 0.2),\n",
    "    y=slice(y1 - 0.2, y2 + 0.2),\n",
    "    chunks={\"time\": 100},\n",
    "    time=\"2012\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Downloading the cutout can take a few seconds or even an hour, depending on your internet connection and whether the dataset\n",
    "was recently requested from the data set provider (and is thus cached on their premise).\n",
    "For us this took ~2 minutes the first time. Preparing it again (a second time) is snappy (for whatever reason you would want to download the same cutout twice).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate capacity layout\n",
    "\n",
    "The capacity layout represents the installed generation capacities in MW in each of the cutout's grid cells.\n",
    "For this example we have generation capacities in kW on a postal code (and partially even more detailed) level.\n",
    "Using the following function, we load the data, fill in geocoordinates where missing for all capacities. \n",
    "\n",
    "Below, the resulting capacities are dissolved to the grid raster using the function `Cutout.layout_from_capacity_list`. The dissolving is done by aggregating the capacities\n",
    "to their respective closest grid cell center obtained from the `cutout.grid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_capacities(typ, cap_range=None, until=None):\n",
    "    \"\"\"\n",
    "    Read in and select capacities.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        typ : str\n",
    "            Type of energy source, e.g. \"Solarstrom\" (PV), \"Windenergie\" (wind).\n",
    "        cap_range : (optional) list-like\n",
    "            Two entries, limiting the lower and upper range of capacities (in kW)\n",
    "            to include. Left-inclusive, right-exclusive.\n",
    "        until : str\n",
    "            String representation of a datetime object understood by pandas.to_datetime()\n",
    "            for limiting to installations existing until this datetime.\n",
    "\n",
    "    \"\"\"\n",
    "    # Load locations of installed capacities and remove incomplete entries\n",
    "    cols = OrderedDict(\n",
    "        (\n",
    "            (\"installation_date\", 0),\n",
    "            (\"plz\", 2),\n",
    "            (\"city\", 3),\n",
    "            (\"type\", 6),\n",
    "            (\"capacity\", 8),\n",
    "            (\"level\", 9),\n",
    "            (\"lat\", 19),\n",
    "            (\"lon\", 20),\n",
    "            (\"validation\", 22),\n",
    "        )\n",
    "    )\n",
    "    database = pd.read_csv(\n",
    "        \"eeg_anlagenregister_2015.08.utf8.csv\",\n",
    "        sep=\";\",\n",
    "        decimal=\",\",\n",
    "        thousands=\".\",\n",
    "        comment=\"#\",\n",
    "        header=None,\n",
    "        usecols=list(cols.values()),\n",
    "        names=list(cols.keys()),\n",
    "        # German postal codes can start with '0' so we need to treat them as str\n",
    "        dtype={\"plz\": str},\n",
    "        parse_dates=[\"installation_date\"],\n",
    "        date_format=\"%d.%m.%Y\",\n",
    "        na_values=(\"O04WF\", \"keine\"),\n",
    "    )\n",
    "\n",
    "    database = database[(database[\"validation\"] == \"OK\") & (database[\"plz\"].notna())]\n",
    "\n",
    "    # Query postal codes <-> coordinates mapping\n",
    "    de_nomi = pgeocode.Nominatim(\"de\")\n",
    "    plz_coords = de_nomi.query_postal_code(database[\"plz\"].unique())\n",
    "    plz_coords = plz_coords.set_index(\"postal_code\")\n",
    "\n",
    "    # Fill missing lat / lon using postal codes entries\n",
    "    database.loc[database[\"lat\"].isna(), \"lat\"] = database[\"plz\"].map(\n",
    "        plz_coords[\"latitude\"]\n",
    "    )\n",
    "    database.loc[database[\"lon\"].isna(), \"lon\"] = database[\"plz\"].map(\n",
    "        plz_coords[\"longitude\"]\n",
    "    )\n",
    "\n",
    "    # Ignore all locations which have not be determined yet\n",
    "    database = database[database[\"lat\"].notna() & database[\"lon\"].notna()]\n",
    "\n",
    "    # Select data based on type (i.e. solar/PV, wind, ...)\n",
    "    data = database[database[\"type\"] == typ].copy()\n",
    "\n",
    "    # Optional: Select based on installation day\n",
    "    if until is not None:\n",
    "        data = data[data[\"installation_date\"] < pd.to_datetime(until)]\n",
    "\n",
    "    # Optional: Only installations within this caprange (left inclusive, right exclusive)\n",
    "    if cap_range is not None:\n",
    "        data = data[\n",
    "            (cap_range[0] <= data[\"capacity\"]) & (data[\"capacity\"] < cap_range[1])\n",
    "        ]\n",
    "\n",
    "    data[\"capacity\"] = data.capacity / 1e3  # convert to MW\n",
    "    return data.rename(columns={\"lon\": \"x\", \"lat\": \"y\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Solar Feed-Ins \n",
    "\n",
    "The layout defines the production capacity per grid cell. Let's see how it looked like in 2012. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacities = load_capacities(\"Solarstrom\", until=\"2012\")\n",
    "solar_layout = cutout.layout_from_capacity_list(capacities, col=\"capacity\")\n",
    "\n",
    "solar_layout.plot(cmap=\"inferno_r\", size=8, aspect=1)\n",
    "plt.title(\"Installed PV in Germany until 2012\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did the total production of this capacity distribution looked like? We pass the layout to the conversion function `cutout.pv`. This calculates the total production over the year. We assume a south orientation (`\"azimuth\": 180.`) and prominent slope 30-35째 for PV in Germany (`\"slope\":30.`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pv = cutout.pv(\n",
    "    panel=\"CSi\", orientation={\"slope\": 30.0, \"azimuth\": 180.0}, layout=solar_layout\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As OPSD also provides data on the total production, let's compare those two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv.squeeze().to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare = (\n",
    "    pd.DataFrame(\n",
    "        dict(atlite=pv.squeeze().to_series(), opsd=opsd[\"DE_solar_generation_actual\"])\n",
    "    )\n",
    "    / 1e3\n",
    ")  # in GW\n",
    "compare.resample(\"1W\").mean().plot(figsize=(8, 5))\n",
    "plt.ylabel(\"Feed-In [GW]\")\n",
    "plt.title(\"PV time-series Germany 2012\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`atlite` also supports to set an **optimal slope** of the panels, using the formula documented in http://www.solarpaneltilt.com/#fixed. The production then looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_opt = cutout.pv(panel=\"CSi\", orientation=\"latitude_optimal\", layout=solar_layout)\n",
    "compare_opt = (\n",
    "    pd.DataFrame(\n",
    "        dict(\n",
    "            atlite=pv_opt.squeeze().to_series(), opsd=opsd[\"DE_solar_generation_actual\"]\n",
    "        )\n",
    "    )\n",
    "    / 1e3\n",
    ")  # in GW\n",
    "compare_opt.resample(\"1W\").mean().plot(figsize=(8, 5))\n",
    "plt.ylabel(\"Feed-In [GW]\")\n",
    "plt.title(\"PV time-series Germany 2012\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about zooming in? Let's plot a specific week. We see that the peaks are differing a bit. In this case `atlite` alternates between over and underestimating a bit... but not too bad given the fact that we are using a reanalysis dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "compare_opt.loc[\"2012-04\"].plot(figsize=(10, 6))\n",
    "plt.ylabel(\"Feed-in [GW]\")\n",
    "plt.title(\"PV time-series Germany April 2012\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    1, 2, subplot_kw={\"aspect\": \"equal\", \"xlim\": [0, 20]}, figsize=(12, 16), sharey=True\n",
    ")\n",
    "compare.plot(x=\"atlite\", y=\"opsd\", kind=\"scatter\", s=1, ax=ax1, title=\"Slope 30째\")\n",
    "compare_opt.plot(\n",
    "    x=\"atlite\", y=\"opsd\", kind=\"scatter\", s=1, ax=ax2, title=\"Slope Optimal\"\n",
    ")\n",
    "\n",
    "ax1.plot([0, 20], [0, 20], c=\"gray\")\n",
    "ax2.plot([0, 20], [0, 20], c=\"gray\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the duration curves of the 30째 slope pv timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "compare[\"atlite\"].sort_values(ascending=False).reset_index(drop=True).plot(\n",
    "    figsize=(10, 6)\n",
    ")\n",
    "compare[\"opsd\"].sort_values(ascending=False).reset_index(drop=True).plot(\n",
    "    figsize=(10, 6)\n",
    ")\n",
    "plt.legend()\n",
    "plt.title(\"Duration curves\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Wind Feed-Ins\n",
    "\n",
    "Now we want to examine the wind potentials in Germany for year 2012. \n",
    "\n",
    "These wind turbines are available in atlite. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in atlite.windturbines:\n",
    "    print(f\"* {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define capacity range to roughly match the wind turbine type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "turbine_categories = [\n",
    "    dict(name=\"Vestas_V25_200kW\", up=400.0),\n",
    "    dict(name=\"Vestas_V47_660kW\", up=700.0),\n",
    "    dict(name=\"Bonus_B1000_1000kW\", up=1100.0),\n",
    "    dict(name=\"Suzlon_S82_1.5_MW\", up=1600.0),\n",
    "    dict(name=\"Vestas_V66_1750kW\", up=1900.0),\n",
    "    dict(name=\"Vestas_V80_2MW_gridstreamer\", up=2200.0),\n",
    "    dict(name=\"Siemens_SWT_2300kW\", up=2500.0),\n",
    "    dict(name=\"Vestas_V90_3MW\", up=50000.0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "low = 0\n",
    "for index, turbine_cat in enumerate(turbine_categories):\n",
    "    capacities = load_capacities(\n",
    "        \"Windkraft\", cap_range=[low, turbine_cat[\"up\"]], until=\"2012\"\n",
    "    )\n",
    "    layout = cutout.layout_from_capacity_list(capacities, \"capacity\")\n",
    "\n",
    "    turbine_categories[index][\"layout\"] = layout\n",
    "    low = turbine_cat[\"up\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a layout for each capacity range, each with a different windturbine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind = xr.Dataset()\n",
    "for turbine_cat in turbine_categories:\n",
    "    name = f\"< {turbine_cat['up']} kW\"\n",
    "    wind[name] = cutout.wind(\n",
    "        turbine=turbine_cat[\"name\"],\n",
    "        layout=turbine_cat[\"layout\"],\n",
    "        show_progress=False,\n",
    "        add_cutout_windspeed=True,\n",
    "    )\n",
    "\n",
    "wind[\"total\"] = sum(wind[c] for c in wind)\n",
    "wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's compare the result with the feed-in statistics from OPSD. We add an extra column for wind turbines with capacity lower than 1600 kW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "compare = pd.DataFrame(\n",
    "    {\n",
    "        \"atlite\": wind[\"total\"].squeeze().to_series(),\n",
    "        \"< 1600 kW\": wind[\"< 1600.0 kW\"].squeeze().to_series(),\n",
    "        \"opsd\": opsd[\"DE_wind_generation_actual\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "compare = compare / 1e3  # in GW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "compare.resample(\"1W\").mean().plot(figsize=(10, 6))\n",
    "plt.ylabel(\"Feed-in [GW]\")\n",
    "plt.title(\"Wind time-series Germany 2012\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "compare.loc[\"2012-04\"].plot(figsize=(10, 6))\n",
    "plt.ylabel(\"Feed-in [GW]\")\n",
    "plt.title(\"Wind time-series Germany April 2012\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ax = compare.plot(x=\"atlite\", y=\"opsd\", kind=\"scatter\", figsize=(12, 8))\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlim(0, 30)\n",
    "ax.plot([0, 30], [0, 30], c=\"gray\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "compare[\"atlite\"].sort_values(ascending=False).reset_index(drop=True).plot(\n",
    "    figsize=(10, 6)\n",
    ")\n",
    "compare[\"opsd\"].sort_values(ascending=False).reset_index(drop=True).plot(\n",
    "    figsize=(10, 6)\n",
    ")\n",
    "plt.legend()\n",
    "plt.title(\"Duration curves\")\n",
    "plt.ylabel(\"Wind Feed-in [GW]\")\n",
    "plt.xlabel(\"Accumulated hours\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks quite aggreeable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting time-series into shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generation time-series can also be aggregated based on shapes.\n",
    "In this example, we aggregate on the basis of the German \"L채nder\" (federal states)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = shpreader.Reader(\n",
    "    shpreader.natural_earth(\n",
    "        resolution=\"10m\", category=\"cultural\", name=\"admin_1_states_provinces\"\n",
    "    )\n",
    ")\n",
    "de_records = list(\n",
    "    filter(lambda r: r.attributes[\"iso_3166_2\"].startswith(\"DE\"), shp.records())\n",
    ")\n",
    "laender = (\n",
    "    gpd.GeoDataFrame([{**r.attributes, \"geometry\": r.geometry} for r in de_records])\n",
    "    .rename(columns={\"iso_3166_2\": \"state\"})\n",
    "    .set_index(\"state\")\n",
    "    .set_crs(4236)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laender.to_crs(3035).plot(figsize=(7, 7))\n",
    "plt.grid(False)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pv = cutout.pv(\n",
    "    panel=\"CSi\",\n",
    "    orientation={\"slope\": 30.0, \"azimuth\": 0.0},\n",
    "    shapes=laender,\n",
    "    layout=solar_layout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production = pv.sum(\"time\").to_series()\n",
    "laender.plot(column=production, figsize=(7, 7), legend=True)\n",
    "plt.grid(False)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production.plot(kind=\"bar\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "git": {
   "suppress_outputs": false
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
